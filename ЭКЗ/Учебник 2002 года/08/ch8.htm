<HTML>
<HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=windows-1251">
<TITLE>Глава 8</TITLE>
</HEAD>
<body lang=RU class="Normal" bgcolor="#FFFFFF">
<p style='text-align:center'><font face="Times New Roman,sans-serif,Courier,mono" size="6"><b> 
  Часть III. Управление памятью.</b></font></p>

<p align="center"><a href="../07/ch7.htm"> Предыдущая глава</a> | 
<a href="../os.html">Программа курса</a> | 
<a href="../09/ch9.htm"> Следующая глава</a></p>


<p style='text-align:justify'>В  данной части изложена идеология построения  системы
  управления памятью в современных ОС.  Центральная концепция управления памятью
   система виртуальной памяти  обеспечивает поддержку  и защиту больших виртуальных
  адресных пространств процессов, составленных из нескольких  логических сегментов.
  Тщательное проектирование аппаратно- зависимых и аппаратно-независимых компонентов
  менеджера памяти, базирующееся на анализе поведения программ (локальности ссылок),
  дает возможность организовать их производительную работу. </p>
<p style='text-align:center'><b><font face="Times New Roman,sans-serif,Courier,mono" size="4">
Глава 8. Введение. Простейшие схемы управления памятью.</font></b></p>
<p style='text-align:justify'><a name="l0801"></a><b>
<font face="Times New Roman,sans-serif,Courier,mono"size="3">8.1 Введение.</font></b></p>
<p style='text-align:justify'>Главная задача компьютерной системы - выполнять
  программы.   Программы,  в течение выполнения, вместе с данными, к которым они
  имеют доступ должны (по крайней мере, частично) находиться  в <i>главной (основной,
  оперативной)</i> памяти. Таким образом, память (<font face="Times New Roman,sans-serif,Courier,mono"size="3">storage</font>,
  <font face="Times New Roman,sans-serif,Courier,mono"size="3">memory</font>) является важнейшим ресурсом, требующим тщательного
  управления. В недавнем прошлом  память  - самый дорогой ресурс.</p>
<p style='text-align:justify'>Часть ОС, которая управляет  памятью, называется
  <i>менеджером памяти</i>. В процессе эволюции в менеджерах памяти современных
  ОС было реализовано несколько основополагающих идей. </p>
<p style='text-align:justify'>Во-первых, это идея <i>сегментации.</i> По-видимому,
  вначале сегменты памяти появились в связи с необходимостью обобществления  процессами
  фрагментов  программного кода (текстовый редактор, тригонометрические библиотеки
  и т.д.),  без чего каждый процесс должен был хранить в своем адресном пространстве
  дублирующую информацию. Эти отдельные участки памяти, хранящие информацию,
  которую система  отображает в память нескольких процессов,  получили название
  <i>сегментов</i>. Память, таким образом, стала двумерной. Адрес состоит из двух
  компонентов: номер сегмента, смещение внутри сегмента. Далее оказалось удобным
  размещать в разных сегментах данные разных типов (код программы, данные, стек
  и т. д.). Попутно выяснилось, что можно контролировать характер работы с конкретным
  сегментом, приписав ему атрибуты, например, права доступа или типы операций,
  разрешенные с данными,  хранящимися в сегменте.  Большинство современных ОС
  поддерживают сегментную организацию памяти (см. раздел, где описана модель памяти
  процесса). В некоторых архитектурах (<font face="Times New Roman,sans-serif,Courier,mono"size="3">Intel</font>, например) сегментация  поддерживается оборудованием.</p>
<p style='text-align:justify'>Вторая идея, о которой можно упомянуть, рассматривая 
  поддержку памяти в  ОС, это разделение памяти<i> на физическую и логическую</i>. 
  Адреса,  к которым обращается процесс, отделяются от адресов, реально существующих 
  в оперативной памяти.  Адрес, сгенерированный  программой, обычно называют <i>логическим 
  (в системах с виртуальной памятью он обычно называется виртуальным)</i> адресом, 
  тогда как адрес, который видит устройство памяти (то есть нечто, загруженное 
  в адресный регистр) обычно называется <i>физическим </i>адресом. Задача ОС, 
  в какой-то момент времени осуществить связывание (или отображение) логического 
  адресного пространства с физическим (<a href="#l0802">см. раздел  8.2</a>).</p>
<p style='text-align:justify'>И, наконец, идея <i>локальности.</i> Свойство локальности
  присуще природе. Пространственная локальность - соседние объекты характеризуются
  похожими свойствами (если в данной местности хорошая погода, то вероятнее всего,
  что в близкой окрестности также хорошая погода). Временная локальность - если
  в 15:00 была хорошая погода, то, вероятно, что и в 14:30 и в 15:30 также наблюдалась
  хорошая погода. Свойство локальности (скорее эмпирическое)  присуще и  работе
  ОС.  Фактически свойство локальности объяснимо, если учесть, как пишутся программы
  и организованы данные, то есть обычно в течение какого-то отрезка времени ограниченный
  фрагмент кода работает с ограниченным набором данных.  Понимание данной особенности
  позволяет организовать <i>иерархию памяти</i>,  используя быструю дорогостоящую
  память  для хранения минимума необходимой информации, размещая оставшуюся часть
  данных на устройствах с более медленным доступом и подкачивая их  в быструю
  память по мере необходимости.  Типичный пример иерархии: регистры процессора,
  кэш процессора, главная память, внешняя память на магнитных дисках (<i>вторичная
  память</i>). </p>
<p style='text-align:justify'><i>Главная</i>  память - это массив слов или байт.
  Каждое слово имеет свой адрес.  Использование вторичной памяти (хранение данных
  на дисках)  в качестве расширения главной дает дополнительные преимущества.
  Во-первых,  главная память слишком мала, чтобы содержать все необходимые программы
  и данные постоянно. Во-вторых,  главная память есть изменчивое (volatile) устройство,
  которое теряет свое содержимое, когда питание отключено или по другим причинам.
  Одно из требований к вторичной памяти - умение хранить большие объемы данных
  постоянно.</p>
<p align="justify"><b>Функциями ОС по управлению
  памятью</b> являются: отображение адресов программы на конкретную область физической
  памяти,  распределение памяти между конкурирующими процессами и защита адресных
  пространств процессов,  выгрузка процессов на диск, когда в оперативной памяти
  недостаточно места для всех процессов, учет свободной и занятой памяти.</p>
<p style='text-align:justify'>Существует несколько схем управления памятью.  Выбор
  той или иной схемы зависит от многих факторов. Рассматривая ту или иную схему
  важно учитывать:</p>
<ul type=disc>
  <li style='text-align:justify;     '>Механизм управления памятью или идеологию
    построения системы управления.</li>
  <li style='text-align:justify;     '>Архитектурные особенности используемой
    системы.</li>
  <li style='text-align:justify;     '>Структуры данных в ОС, используемые для
    управления памятью.</li>
  <li style='text-align:justify;     '>Алгоритмы, используемые для управления
    памятью.</li>
</ul>
<p style='text-align:justify'>Вначале будут рассмотрены простейшие схемы, затем,
  описана доминирующая на сегодня схема виртуальной памяти, ее аппаратная и программная
  поддержка.</p>
<p style='text-align:justify'><a name="l0802"></a><b>
<font face="Times New Roman,sans-serif,Courier,mono"size="3">8.2 Связывание адресов.</font></b></p>
<p style='text-align:justify'>Одна из функций управления памятью  отображение
  информации в память. Отображение   обычно понимается как преобразование адресных
  пространств.  </p>
<p style='text-align:justify'>Как уже упоминалось в <a href="#l0801">разделе 8.1</a>, адреса, с которыми
  имеет дело менеджер памяти, бывают  логические (виртуальные для систем с виртуальной
  памятью) и физические.</p>
<p style='text-align:justify'> Пользовательская программа не видит реальных физических
  адресов, а имеет дело с логическими адресами, которые являются результатом трансляции
  символьных имен программы. Логические адреса обычно образуются  на этапе создания
  загрузочного модуля (линковки программы).</p>
<p style='text-align:justify'> </p>
<p style='text-align:justify'>Набор адресов, сгенерированный программой, называют 
  <i>логическим (виртуальным) адресным пространством</i>, которому соответствует 
  <i>физическое адресное пространство</i>.</p>
<p style='text-align:justify'>Максимальный размер логического адресного пространства
  обычно определяется  разрядностью процессора (например, 2**32) и в современных
  системах значительно превышает размер физического адресного пространства.</p>
<p style='text-align:justify'>Связывание логического адреса,  порожденного оператором
  программы, с физическим должно быть осуществлено  до начала выполнения оператора
  или в момент его выполнения.</p>
<p style='text-align:justify'>Обычно программа  проходит нескольких шагов:  </p>
<ul>
  <li>
    <p style="text-align:justify">текст на алгоритмическом языке,</li>
  <li>объектный модуль, </li>
  <li>загрузочный модуль,</li>
  <li>бинарный образ в памяти.</li>
</ul>
<p style='text-align:justify'>Используемые программой адреса  в каждом конкретном
  случае могут быть представлены различными способами. Например, адреса в исходных
  текстах обычно символические.  Компилятор связывает эти символические адреса
  с перемещаемыми  адресами (такими как <font face="Times New Roman,sans-serif,Courier,mono"size="3">n</font> байт от начала
  модуля).  Загрузчик или линкер, в свою очередь, связывают эти перемещаемые адреса
  с виртуальными адресами.  Каждое связывание - отображение одного адресного пространства
  в другое.  </p>
<p style='text-align:justify'><img border="0" src="images/image001.gif" width="561" height="276"></p>
<p style='text-align:justify'><font size="2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
Рис.  8.1  Этапы связывания адресов.</font></p>
<p style='text-align:justify'>Привязка инструкций и данных к памяти в принципе
  может быть, таким образом,  сделана на  следующих шагах:</p>
<ul>
  <li>
    <p style="text-align:justify;">Этап компиляции (Compile time).  Когда на стадии компиляции известно
  точное место размещения процесса в памяти, тогда генерируются абсолютные адреса.
  Если стартовый адрес программы меняется, необходимо перекомпилировать код.
  В качестве примера можно привести .com программы  <font face="Times New Roman,sans-serif,Courier,mono"size="3">MS</font>-<font face="Times New Roman,sans-serif,Courier,mono"size="3">DOS</font>,
  которые  связывают ее с физическими  адресами на стадии компиляции.</li>
  <li>
    <p style="text-align:justify;">Этап загрузки (Load time).  Если на стадии компиляции не известно
  где процесс будет размещен в памяти, компилятор генерирует перемещаемый код.
  В этом случае окончательное связывание откладывается до момента загрузки. Если
  стартовый адрес меняется,  нужно всего лишь перезагрузить код с учетом измененной
  величины.</li>
  <li>
    <p style="text-align:justify;">Этап выполнения (Execution time).  Если процесс может быть перемещен
  во время выполнения из одного сегмента памяти в другой, связывание откладывается
  до времени выполнения.  Здесь желательно специализированное оборудование, например
  регистры перемещения. Их значение прибавляется к каждому адресу, сгенерированному
  процессом. Например, <font face="Times New Roman,sans-serif,Courier,mono"size="3">MS</font>-<font face="Times New Roman,sans-serif,Courier,mono"size="3">DOS</font> использует четыре таких (сегментных)
  регистра.</li>
</ul>
<p style='text-align:justify'><a name="l0803"></a><b>
<font face="Times New Roman,sans-serif,Courier,mono" size="3">8.3 Простейшие схемы управления памятью.</font></b></p>
<p style='text-align:justify'>ОС начали свое существование с применения очень 
  простых методов управления памятью. Применявшаяся техника распространялась от 
  статического распределения памяти (каждый процесс пользователя должен полностью 
  поместиться в основной памяти, и система принимает к обслуживанию дополнительные 
  пользовательские процессы до тех пор, пока все они одновременно помещаются в 
  основной памяти), с промежуточным решением в виде &quot;простого свопинга&quot; 
  (система по-прежнему располагает каждый процесс в основной памяти целиком, но 
  иногда на основании некоторого критерия целиком сбрасывает образ некоторого 
  процесса из основной памяти во внешнюю память и заменяет его в основной памяти 
  образом некоторого другого процесса).  Схемы такого рода  имеют не только историческую 
  ценность. В настоящее время  они применяются в учебных  и научно-исследовательских 
  модельных ОС, а также в ОС для встроенных (<font face="Times New Roman,sans-serif,Courier,mono"size="3">embedded</font>) 
  компьютеров.</p>
<p style='text-align:justify'><a name="l080301"></a><b>
<font face="Times New Roman,sans-serif,Courier,mono" size="3">8.3.1 Схема с фиксированными разделами.</font></b></p>
<p style='text-align:justify'>Самым простым способом управления оперативной памятью
  является ее предварительное (обычно на этапе генерации или в момент загрузки
  системы) разбиение на несколько разделов фиксированной величины.  По мере прибытия
  процесс помещается в тот или иной раздел. </p>
<p style='text-align:justify'>Как правило, происходит условное разбиение физического 
  адресного пространства. Связывание логических адресов процесса и физических 
  происходит на этапе его загрузки в конкретный раздел.</p>
<p style='text-align:justify'>Каждый раздел может иметь свою очередь или может
  существовать глобальная очередь  для всех разделов.</p>
<p style='text-align:justify'><img border="0" src="images/image002.gif" width="557" height="278"></p>
<p style='text-align:justify'><font size="2">Рис. 8.2  Схема с фиксированными разделами:  (<font face="Times New Roman,sans-serif,Courier,mono"size="3">a</font>)
  с общей очередью процессов,  (<font face="Times New Roman,sans-serif,Courier,mono"size="3">b</font>) с отдельными очередями
  процессов.</font></p>
<p style='text-align:justify'>Эта схема была  реализована в IBM OS/360 (MFT) и
  в <font face="Times New Roman,sans-serif,Courier,mono"size="3">DEC</font><font face="Times New Roman,sans-serif,Courier,mono"size="3"> </font><font face="Times New Roman,sans-serif,Courier,mono"size="3">RSX</font>-11.</p>
<p style='text-align:justify'>Подсистема управления памятью сравнивает размер
  программы, поступившей на выполнение, выбирает подходящий раздел,  осуществляет
  загрузку программы и настройку адресов. </p>
<p style='text-align:justify'>В какой раздел помещать программу?  Распространены
  три стратегии:</p>
<ul>
  <li>
    <p style="text-align:justify;">Стратегия первого подходящего (<font face="Times New Roman,sans-serif,Courier,mono"size="3">First</font><font face="Times New Roman,sans-serif,Courier,mono"size="3">
  </font><font face="Times New Roman,sans-serif,Courier,mono"size="3">fit</font>). Задание помещается  в первый подходящий по размеру раздел.</li>
  <li>
    <p style="text-align:justify;">Стратегия наиболее подходящего (<font face="Times New Roman,sans-serif,Courier,mono"size="3">Best</font><font face="Times New Roman,sans-serif,Courier,mono"size="3">
  </font><font face="Times New Roman,sans-serif,Courier,mono"size="3">fit</font>). Задание помещается  в тот раздел, где ему наиболее тесно.</li>
  <li>
    <p style="text-align:justify;">Стратегия наименее подходящего (<font face="Times New Roman,sans-serif,Courier,mono"size="3">Worst</font><font face="Times New Roman,sans-serif,Courier,mono"size="3">
  </font><font face="Times New Roman,sans-serif,Courier,mono"size="3">fit</font>).  При помещении в самый большой раздел в нем остается достаточно
  места для возможного размещения еще одного процесса.</li>
</ul>
<p style='text-align:justify'>Моделирование показало, что с точки зрения утилизации
  памяти  и уменьшения времени первые два способа лучше. С точки зрения утилизации
  первые два примерно одинаковы, но первый способ быстрее. Попутно заметим, что
  перечисленные стратегии широко применяются и другими компонентами ОС, например,
  для размещения файлов на диске.</p>
<p style='text-align:justify'><font face="Times New Roman,sans-serif,Courier,mono" size="3">Связывание (настройка) адресов для данной схемы возможны как на этапе компиляции,
  так и на этапе загрузки. </font></p>
<p style='text-align:justify'>Очевидный недостаток этой схемы  число одновременно
  выполняемых процессов ограничено числом разделов.</p>
<p style='text-align:justify'>Другим существенным недостатком является то, что
  предлагаемая схема сильно страдает от <i>внешней фрагментации</i>  потери памяти,
  не используемой ни одним процессом. Фрагментация возникает потому, что процесс
  не полностью занимает выделенный ему раздел или  вследствие не использования
  некоторых разделов, которые  слишком малы для выполняемых пользовательских программ.</p>
<p style='text-align:justify'><i>8.3.1.1  Один процесс в памяти</i></p>
<p style='text-align:justify'>Частный случай схемы с фиксированными разделами
   работа менеджера памяти однозадачной ОС.  В памяти размещается один пользовательский
  процесс. Остается определить, где располагается пользовательская  программа
  по отношению к ОС - сверху, снизу или посередине. Причем часть ОС может быть
  в ROM (например, BIOS,  драйверы устройств). Главный фактор, влияющий на это
  решение - расположение вектора прерываний, который обычно локализован в нижней
  части памяти,  поэтому ОС также размещают в нижней. Примером такой организации
  может служить ОС <font face="Times New Roman,sans-serif,Courier,mono"size="3">MS</font>-<font face="Times New Roman,sans-serif,Courier,mono"size="3">DOS</font>.</p>
<p style='text-align:justify'>Чтобы пользовательская программа не портила кода
  ОС,  требуется защита ОС,  которая может быть организована  при помощи одного
  граничного регистра, содержащего адрес границы ОС.  </p>
<p style='text-align:justify'><i>8.3.1.2   Оверлейная структура</i></p>
<p style='text-align:justify'>Так как размер логического адресного пространства 
  процесса может быть больше чем  размер выделенного ему раздела (или больше чем 
  размер самого большого раздела), иногда используется техника, называемая оверлей 
  (overlay) или организация структуры с перекрытием.  Основная идея - держать 
  в памяти только те инструкции программы, которые нужны в данный момент времени. 
</p>
<p style='text-align:justify'>Потребность в таком способе загрузки появляется,
  если логическое адресное пространство  системы мало, например 1 мегабайт (<font face="Times New Roman,sans-serif,Courier,mono"size="3">MS</font>-<font face="Times New Roman,sans-serif,Courier,mono"size="3">DOS</font>) или даже всего 64 килобайта
  (<font face="Times New Roman,sans-serif,Courier,mono"size="3">PDP</font>-11), а программа относительно велика. На современных 32-разрядных
  системах, где  виртуальное адресное пространство измеряется гигабайтами, проблемы
  с нехваткой памяти решаются другими способами (см. раздел Виртуальная память).</p>
<p style='text-align:justify'><img border="0" src="images/image003.gif" width="574" height="243"></p>
<p style='text-align:justify'><font size="2">Рис 8.3 . Организация структуры с перекрытием. Можно
  поочередно загружать в память ветви <font face="Times New Roman,sans-serif,Courier,mono"size="3">A</font>-<font face="Times New Roman,sans-serif,Courier,mono"size="3">B</font>, <font face="Times New Roman,sans-serif,Courier,mono"size="3">A</font>-<font face="Times New Roman,sans-serif,Courier,mono"size="3">C</font>-<font face="Times New Roman,sans-serif,Courier,mono"size="3">D</font>
  и <font face="Times New Roman,sans-serif,Courier,mono"size="3">A</font>-<font face="Times New Roman,sans-serif,Courier,mono"size="3">C</font>-<font face="Times New Roman,sans-serif,Courier,mono"size="3">E</font> программы.</font></p>
<p style='text-align:justify'>Коды  ветвей  оверлейной  структуры программы находятся 
  на диске как абсолютные образы памяти и считываются драйвером оверлеев при необходимости. 
  Для конструирования оверлеев необходимы специальные алгоритмы перемещения и 
  связывания. Для описания оверлейной структуры обычно используется  специальный 
  несложный язык (<font face="Times New Roman,sans-serif,Courier,mono"size="3">overlay</font><font face="Times New Roman,sans-serif,Courier,mono"size="3"> 
  </font><font face="Times New Roman,sans-serif,Courier,mono"size="3">description</font><font face="Times New Roman,sans-serif,Courier,mono"size="3"> 
  </font><font face="Times New Roman,sans-serif,Courier,mono"size="3">language</font>). 
  Совокупность файлов исполняемой программы дополняется файлом (обычно с расширением 
  .<font face="Times New Roman,sans-serif,Courier,mono"size="3">odl</font>), описывающим 
  дерево вызовов внутри программы.  Например, для примера, приведенного на рис. 
  8.3 , текст этого файла может выглядеть так:<font face="Times New Roman,sans-serif,Courier,mono"size="3"></font></p>
<p style='text-align:justify'><font face="Times New Roman,sans-serif,Courier,mono"size="3"><i>A-(B,C)</i></font></p>
<p style='text-align:justify'><font face="Times New Roman,sans-serif,Courier,mono"size="3"><i>C-(D,E)</i></font></p>
<p style='text-align:justify'>Синтаксис подобного файла может распознаваться
  загрузчиком. Привязка к памяти происходит в момент  очередной загрузки одной
  из ветвей программы.</p>
<p style='text-align:justify'> Оверлеи не требуют специальной поддержки со стороны
  ОС. Они могут быть полностью реализованы на пользовательском уровне с простой
  файловой структурой.  ОС лишь делает несколько больше операций ввода-вывода.
  Типовое решение  порождение линкером специальных команды, которые включают
  загрузчик каждый раз: когда требуется обращение к одной из перекрывающихся ветвей
  программы.</p>
<p style='text-align:justify'>Программист должен тщательно проектировать оверлейную
  структуру. Это требует полного знания структуры программы, кода, данных, языка
  описания оверлейной структуры.  По этой причине применение оверлеев ограничено
  компьютерами с лимитами на память и т.д. <font face="Times New Roman,sans-serif,Courier,mono"size="3"> </font>Как мы увидим в дальнейшем
  проблема оверлейных сегментов, контролируемых программистом, отпадает благодаря
  появлению систем виртуальной  памяти.</p>
<p style='text-align:justify'>Заметим, что здесь мы впервые сталкиваемся со свойством
  локальности, которое дает возможность хранить в памяти только ту информацию,
  которая необходима в каждый конкретный момент вычислений.</p>
<p style='text-align:justify'><a name="l080302"></a> <b>8.3.2  Свопинг</b></p>
<p style='text-align:justify'>Имея дело с пакетными системами можно обходиться 
  фиксированными разделами и не использовать ничего более сложного. В системах 
  с разделением времени возможна ситуация, когда память не в состоянии содержать 
  все пользовательские  процессы.  Приходится прибегать к  свопингу (<font face="Times New Roman,sans-serif,Courier,mono"size="3">s</font>wapping) 
  - перемещению процессов из главной памяти на диск и обратно целиком.  Частичная 
  выгрузка процессов на диск  связана с пейджингом (<font face="Times New Roman,sans-serif,Courier,mono"size="3">paging</font>) 
  будет рассмотрена ниже.</p>
<p style='text-align:justify'>Выгруженный процесс может быть возвращен  в то же
  самое адресное пространство или  в другое. Это ограничение диктуется методом
  связывания. Для схемы  связывания  на этапе выполнения  можно загрузить процесс
  в другое  место памяти.</p>
<p style='text-align:justify'>Свопинг не имеет непосредственного отношения к
  управлению памятью, скорее он связан с подсистемой планирования процессов. В
  системах со свопингом время переключения контекстов лимитируется временем
  загрузки  выгрузки процессов. Для эффективной утилизации процессора необходимо,
  чтобы величина кванта времени   существенно  его превышала </p>
<p style='text-align:justify'>Оптимизация свопинга может быть связана с выгрузкой
  лишь реально используемой памяти или выгрузкой процессов, реально не функционирующих.
  Кроме того,  выгрузка обычно осуществляется в специально отведенное пространство
  для свопинга, то есть быстрее, чем  через стандартную файловую систему (пространство
  выделяется большими блоками, поиск файлов и методы непосредственного выделения
  не используются).</p>
<p style='text-align:justify'>Во многих версиях Unix свопинг обычно запрещен, 
  однако он стартует, когда возрастает загрузка системы. </p>
<h3 style='text-align:justify'><a name="_Toc493394645"></a><a name="l080303"><b>
<font face="Times New Roman,sans-serif,Courier,mono" size="3">8.3.3 Мультипрограммирование с переменными разделами.</font></b></a><b><font face="Times New Roman,sans-serif,Courier,mono"size="3"></font></b></h3>
<p style='text-align:justify'>В принципе, система свопинга может базироваться 
  на фиксированных разделах. На практике, однако,  использование фиксированных 
  разделов приводит к большим потерям используемой памяти, когда задача существенно 
  меньше раздела. </p>
<p style='text-align:justify'>Более эффективной представляется схема с переменными 
  (динамическими) разделами. В этом случае вначале вся память свободна и не разделена 
  заранее на разделы. Вновь поступающей задаче выделяется необходимая память. 
  После выгрузки процесса память временно освобождается.  По истечении некоторого 
  времени память представляет собой набор занятых и свободных участков  (рис. 
  8.4)   Смежные свободные участки могут быть объединены в один.</p>
<p style='text-align:justify'><img border="0" src="images/image004.gif" width="542" height="342"></p>
<p style='text-align:justify'><font size="2">Рис. 8.4  Динамика распределения памяти между процессами.
  Серым цветом показана неиспользуемая  память.</font></p>
<p style='text-align:justify'>Типовой цикл работы менеджера памяти состоит в анализе 
  запроса на выделение свободного участка (раздела), выборке его среди имеющихся 
  в соответствие с одной из стратегий  (<font face="Times New Roman,sans-serif,Courier,mono"size="3">first</font><font face="Times New Roman,sans-serif,Courier,mono"size="3"> 
  </font><font face="Times New Roman,sans-serif,Courier,mono"size="3">fit</font>, 
  <font face="Times New Roman,sans-serif,Courier,mono"size="3">best</font><font face="Times New Roman,sans-serif,Courier,mono"size="3"> 
  </font><font face="Times New Roman,sans-serif,Courier,mono"size="3">fit</font>, 
  <font face="Times New Roman,sans-serif,Courier,mono"size="3">worst</font><font face="Times New Roman,sans-serif,Courier,mono"size="3"> 
  </font><font face="Times New Roman,sans-serif,Courier,mono"size="3">fit</font>),  
  загрузке процесса в выбранный раздел и последующем внесении изменений в таблицы 
  свободных и занятых областей. Аналогичная корректировка необходима и после завершения 
  процесса. Связывание адресов может быть осуществлено на этапах загрузки и выполнения.</p>
<p style='text-align:justify'>Этот метод более гибок по сравнению с методом фиксированных
  разделов</p>
<p style='text-align:justify'>Этому методу также присуща внешняя фрагментация
  вследствие наличия большого числа участков свободной памяти. Проблемы фрагментации
  могут быть различными. В худшем случае мы можем иметь участок свободной (потерянной)
  памяти между двумя процессами. Если все эти куски объединить в один блок, мы
  смогли бы разместить больше процессов. Выбор между first-fit и best-fit слабо
  влияет на величину фрагментации. </p>
<p style='text-align:justify'>В зависимости от суммарного размера памяти и среднего
  размера процесса эта проблема может быть большей или меньшей. Статистический
  анализ показывает, что при наличии n блоков пропадает n/2 блоков, то есть 1/3
  памяти! Это известное 50% правило (два соседних свободных участка в отличие
  от двух соседних процессов могут быть объединены в один).</p>
<p style='text-align:justify'>Одно из решений проблемы внешней фрагментации - 
  разрешить адресному пространству процесса не быть непрерывным, что разрешает 
  выделять процессу память в любых доступных местах. Один из способов реализации 
  такого решения - это paging , используемый во многих современных ОС (будет рассмотрен 
  ниже).</p>
<p style='text-align:justify'>Другим способом борьбы с внешней фрагментацией является
  <i>сжатие</i>, то есть перемещение всех занятых (свободных) участков в сторону
  возрастания (убывания) адресов, так, чтобы вся свободная память образовала непрерывную
  область. Этот метод иногда называют схемой с <i>перемещаемыми разделами</i>.
  В идеале фрагментация после сжатия должна отсутствовать. </p>
<p style='text-align:justify'>Сжатие, однако, является дорогостоящей процедурой, 
  алгоритм выбора оптимальной стратегии сжатия очень труден, и, как правило, сжатие 
  осуществляется в комбинации с выгрузкой и загрузкой по другим адресам.</p>
<h4 style='text-align:justify'><a name="l0804"></a> <font face="Times New Roman,sans-serif,Courier,mono" size="3">8.4 
  Резюме </font></h4>
<p style='text-align:justify'>Итак, в настоящей главе рассмотрены простейшие способы 
  организации работы менеджера оперативной памяти. В последующих главах будут 
  излагаться современные решения, связанные с поддержкой виртуальной памяти.</p>

<p align="center"><a href="../07/ch7.htm"> Предыдущая глава</a> | 
<a href="../os.html">Программа курса</a> | 
<a href="../09/ch9.htm"> Следующая глава</a></p>

</body>
</html>
